{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 눈 사진 캡쳐\n",
    "눈 감은 거 1000장\n",
    "실눈 ~ 정상 ~ 큰눈 1000장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 및 모듈 임포트\n",
    "import cv2  # OpenCV: 영상 처리 라이브러리\n",
    "import dlib  # dlib: 얼굴 및 객체 검출 라이브러리\n",
    "import numpy as np  # NumPy: 수학 및 행렬 연산 라이브러리\n",
    "from imutils import face_utils  # imutils: OpenCV를 좀 더 편리하게 사용하기 위한 보조 라이브러리\n",
    "from keras.models import load_model  # Keras: 딥러닝 모델을 쉽게 구축하고 훈련하기 위한 라이브러리\n",
    "\n",
    "# 상수 정의\n",
    "IMG_SIZE = (34, 26)  # 눈 이미지 크기\n",
    "\n",
    "# dlib을 사용하여 얼굴 및 랜드마크 검출을 위한 초기화\n",
    "detector = dlib.get_frontal_face_detector()  # 얼굴 감지기 초기화\n",
    "predictor = dlib.shape_predictor('models/shape_predictor_68_face_landmarks.dat')  # 얼굴 랜드마크 예측기 초기화\n",
    "\n",
    "# 미리 학습된 모델 로드\n",
    "model = load_model('models/models/2023_12_26_11_40_10.h5')  # 학습된 눈 감지 모델 로드\n",
    "model.summary()  # 모델 구조 출력\n",
    "\n",
    "# 눈을 자르고 크기를 조절하는 함수 정의\n",
    "def crop_eye(img, eye_points):\n",
    "    # 눈 영역의 경계 좌표 계산\n",
    "    x1, y1 = np.amin(eye_points, axis=0)\n",
    "    x2, y2 = np.amax(eye_points, axis=0)\n",
    "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "    w = (x2 - x1) * 1.2\n",
    "    h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "    margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "    min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "    max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "    eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(int)\n",
    "\n",
    "    # 이미지에서 눈 영역을 잘라냄\n",
    "    eye_img = img[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "    return eye_img, eye_rect\n",
    "\n",
    "# 웹캠 열기\n",
    "capture = cv2.VideoCapture(1)  # 디바이스 아이디\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 2560)  # 웹캠 가로 해상도 설정\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 1440)  # 웹캠 세로 해상도 설정\n",
    "\n",
    "count = 1590  # 이미지 파일 저장을 위한 카운터 초기화\n",
    "\n",
    "while cv2.waitKey(10) < 0:  # wait를 늘리면 프레임이 줄어듬\n",
    "    ret, img_ori = capture.read()\n",
    "    img = img_ori.copy()\n",
    "    \n",
    "    # 그레이스케일로 변환\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 얼굴 및 랜드마크 검출\n",
    "    faces = detector(gray)\n",
    "    face = faces[0]\n",
    "    shapes = predictor(gray, face)\n",
    "    shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "    # 두 눈을 자르고 크기를 조절\n",
    "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "    # 눈 이미지 크기 조절 및 좌우 반전\n",
    "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "    # 이미지 저장 경로 및 파일명 설정\n",
    "    path_l = f'media/closeEye/{count}.png'\n",
    "    cv2.imwrite(path_l, eye_img_l)\n",
    "    count += 1  # 카운터 증가\n",
    "    path_r = f'media/closeEye/{count}.png'\n",
    "    cv2.imwrite(path_r, eye_img_r)\n",
    "    count += 1  # 카운터 증가\n",
    "\n",
    "    # 모델 입력 형태로 이미지 전처리\n",
    "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "    # 모델 예측\n",
    "    pred_l = model.predict(eye_input_l)\n",
    "    pred_r = model.predict(eye_input_r)\n",
    "\n",
    "    # 결과 시각화\n",
    "    state_l = 'Open %.1f' if pred_l > 0.1 else 'Close %.1f'\n",
    "    state_r = 'Open %.1f' if pred_r > 0.1 else 'Close %.1f'\n",
    "\n",
    "    state_l = state_l % pred_l\n",
    "    state_r = state_r % pred_r\n",
    "\n",
    "    # 결과 시각화를 위한 사각형 및 텍스트 추가\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "    cv2.putText(img, state_l, tuple(eye_rect_l[1:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(img, state_r, tuple(eye_rect_r[1:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "    # 결과 출력\n",
    "    cv2.imshow('result', img)\n",
    "\n",
    "# 웹캠 해제\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 눈 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 이미지를 읽고 지정된 크기로 조정하는 함수\n",
    "def read_and_resize(file_path, target_size=(34, 26)):\n",
    "    img = Image.open(file_path)\n",
    "    img = img.resize(target_size, Image.ANTIALIAS)\n",
    "    return np.array(img)\n",
    "\n",
    "# 각각의 이미지 파일이 저장된 폴더 경로\n",
    "open_folder_path = \".media/openEye/\"\n",
    "close_folder_path = \".media/closeEye/\"\n",
    "\n",
    "# 각 폴더에 있는 이미지 파일들의 경로를 리스트로 수집\n",
    "open_image_files = [os.path.join(open_folder_path, f) for f in os.listdir(open_folder_path) if f.endswith(\".png\")]\n",
    "close_image_files = [os.path.join(close_folder_path, f) for f in os.listdir(close_folder_path) if f.endswith(\".png\")]\n",
    "\n",
    "# 이미지 데이터를 읽어서 리스트에 추가\n",
    "image_data = []\n",
    "state = []\n",
    "\n",
    "# 눈 뜬 사진 추가\n",
    "for open_file in open_image_files:\n",
    "    open_data = read_and_resize(open_file)\n",
    "    image_data.append(open_data)\n",
    "    state.append(\"open\")\n",
    "\n",
    "# 눈 감은 사진 추가\n",
    "for close_file in close_image_files:\n",
    "    close_data = read_and_resize(close_file)\n",
    "    image_data.append(close_data)\n",
    "    state.append(\"close\")\n",
    "\n",
    "# 데이터셋 생성\n",
    "data = pd.DataFrame({\"state\": state, \"image\": image_data})\n",
    "\n",
    "# 데이터를 랜덤하게 섞은 후 훈련 데이터와 검증 데이터로 분할\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# CSV 파일로 저장\n",
    "print(\"image_data\", np.array(image_data))\n",
    "print(\"data\", data)\n",
    "data.to_csv(\"dataset/eye/dataset.csv\", index=False)\n",
    "train_data.to_csv(\"dataset/eye/train_dataset.csv\")\n",
    "val_data.to_csv(\"dataset/eye/val_dataset.csv\")\n",
    "\n",
    "# 이미지 데이터를 NumPy 배열로 변환\n",
    "x_train = np.array(train_data[\"image\"].tolist()).astype(np.float32)\n",
    "x_val = np.array(val_data[\"image\"].tolist()).astype(np.float32)\n",
    "\n",
    "# 레이블을 NumPy 배열로 변환\n",
    "y_train = np.array(train_data[\"state\"].map({\"open\": 1, \"close\": 0})).reshape(-1, 1).astype(np.float32)\n",
    "y_val = np.array(val_data[\"state\"].map({\"open\": 1, \"close\": 0})).reshape(-1, 1).astype(np.float32)\n",
    "\n",
    "# NumPy 배열을 파일로 저장\n",
    "np.save(\"dataset/eye/x_train.npy\", x_train)\n",
    "np.save(\"dataset/eye/x_val.npy\", x_val)\n",
    "np.save(\"dataset/eye/y_train.npy\", y_train)\n",
    "np.save(\"dataset/eye/y_val.npy\", y_val)\n",
    "\n",
    "# 출력 확인\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 입술 따기\n",
    "입 다문 거 500장, 말하는 거 500장  \n",
    "하품하듯이 입 크게 벌린 거 1000장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import os\n",
    "\n",
    "# 얼굴 랜드마크 모델 로드\n",
    "predictor_path = \"models/shape_predictor_68_face_landmarks.dat\"  # 모델 경로를 실제 파일 경로로 변경해주세요\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "# 얼굴 감지기 로드\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# 웹캠 열기\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "# 웹캠 해상도 설정 (720p)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)  # 가로 해상도\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)   # 세로 해상도\n",
    "\n",
    "# 웹캠 프레임 속도 설정 (60fps)\n",
    "cap.set(cv2.CAP_PROP_FPS, 60)\n",
    "\n",
    "# 크롭할 이미지 크기\n",
    "crop_size = 100\n",
    "\n",
    "# ??번째부터\n",
    "current_frame = 1200\n",
    "\n",
    "# +100번째까지\n",
    "num_frames_to_capture = current_frame + 100\n",
    "\n",
    "\n",
    "\n",
    "while current_frame < num_frames_to_capture:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # BGR 이미지를 그레이스케일로 변환\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 얼굴 감지\n",
    "    faces = detector(gray_frame)\n",
    "\n",
    "    # 얼굴이 감지되었다면\n",
    "    if faces:\n",
    "        # 가장 큰 얼굴 1개 찾기\n",
    "        largest_face = max(faces, key=lambda rect: (rect.width() * rect.height()))\n",
    "\n",
    "        # 얼굴 랜드마크 예측\n",
    "        landmarks = predictor(gray_frame, largest_face)\n",
    "\n",
    "        # 입술 중심 좌표 계산\n",
    "        lip_center_x = sum(point.x for point in landmarks.parts()[48:60]) // 12\n",
    "        lip_center_y = sum(point.y for point in landmarks.parts()[48:60]) // 12\n",
    "\n",
    "        # 입 중심을 기준으로 10 x 10 크롭\n",
    "        lip_min_x = max(0, lip_center_x - crop_size // 2)\n",
    "        lip_max_x = min(gray_frame.shape[1], lip_center_x + crop_size // 2)\n",
    "        lip_min_y = max(0, lip_center_y - crop_size // 2)\n",
    "        lip_max_y = min(gray_frame.shape[0], lip_center_y + crop_size // 2)\n",
    "\n",
    "        lip_region = gray_frame[lip_min_y:lip_max_y, lip_min_x:lip_max_x]\n",
    "\n",
    "        # 이미지 저장\n",
    "        save_path = f\"media/openLip/{current_frame}.png\"  # 저장\n",
    "        cv2.imwrite(save_path, lip_region)\n",
    "        print(f\"Frame {current_frame} saved at {save_path}\")\n",
    "\n",
    "        current_frame += 1\n",
    "\n",
    "    # 화면에 표시\n",
    "    cv2.imshow(\"Lip Landmark Detection\", gray_frame)\n",
    "\n",
    "    # 'q' 키를 누르면 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 웹캠 해제 및 창 닫기\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 입 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wl/5h8ygnjj29ndbpccd4zxqbfh0000gn/T/ipykernel_59133/1696903667.py:10: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  img = img.resize(target_size, Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_data [[[122 145 152 ... 153 154 146]\n",
      "  [117  94  94 ... 125 147 149]\n",
      "  [ 51   9  18 ...  46  53 100]\n",
      "  ...\n",
      "  [115  93  90 ... 102 117 128]\n",
      "  [123 103  95 ... 112 131 128]\n",
      "  [121 121 101 ... 125 131 126]]\n",
      "\n",
      " [[161 185 181 ... 196 194 188]\n",
      "  [173 165 143 ... 158 181 183]\n",
      "  [172 141 117 ...  88 117 163]\n",
      "  ...\n",
      "  [177 181 176 ... 160 179 170]\n",
      "  [170 179 166 ... 170 161 178]\n",
      "  [160 175 167 ... 150 173 181]]\n",
      "\n",
      " [[118 143 146 ... 159 171 163]\n",
      "  [113  84  96 ... 113 124 147]\n",
      "  [ 51   6  24 ...  42  26  59]\n",
      "  ...\n",
      "  [116  93  92 ...  86 102 130]\n",
      "  [121 101  99 ... 133 121 133]\n",
      "  [119 117 102 ... 123 128 133]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[158 151 128 ... 166 178 189]\n",
      "  [160 156 164 ... 189 180 185]\n",
      "  [153 163 160 ... 163 192 183]\n",
      "  ...\n",
      "  [125 112 102 ... 103 116 131]\n",
      "  [125 120 111 ... 125 131 134]\n",
      "  [136 137 131 ... 152 154 151]]\n",
      "\n",
      " [[134 145 133 ... 156 158 157]\n",
      "  [142 145 151 ... 171 163 165]\n",
      "  [143 154 160 ... 183 178 165]\n",
      "  ...\n",
      "  [129 125 117 ... 118 128 135]\n",
      "  [135 130 119 ... 126 139 146]\n",
      "  [143 144 134 ... 155 163 164]]\n",
      "\n",
      " [[161 159 151 ... 127 127 132]\n",
      "  [166 164 159 ... 136 139 147]\n",
      "  [143 154 178 ... 154 155 155]\n",
      "  ...\n",
      "  [170 168 157 ... 144 150 151]\n",
      "  [163 170 167 ... 157 162 160]\n",
      "  [159 160 165 ... 166 168 167]]]\n",
      "data       state                                              image\n",
      "0      open  [[122, 145, 152, 143, 142, 142, 143, 153, 154,...\n",
      "1      open  [[161, 185, 181, 184, 178, 174, 184, 196, 194,...\n",
      "2      open  [[118, 143, 146, 135, 124, 120, 133, 159, 171,...\n",
      "3      open  [[109, 100, 105, 109, 114, 127, 133, 146, 161,...\n",
      "4      open  [[188, 187, 168, 153, 146, 146, 147, 155, 169,...\n",
      "...     ...                                                ...\n",
      "1995  close  [[140, 152, 151, 153, 162, 140, 131, 136, 149,...\n",
      "1996  close  [[161, 162, 136, 123, 124, 128, 140, 153, 168,...\n",
      "1997  close  [[158, 151, 128, 132, 154, 165, 170, 166, 178,...\n",
      "1998  close  [[134, 145, 133, 118, 119, 126, 146, 156, 158,...\n",
      "1999  close  [[161, 159, 151, 139, 136, 132, 133, 127, 127,...\n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "(1600, 10, 10) (1600, 1)\n",
      "(400, 10, 10) (400, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 이미지를 읽고 지정된 크기로 조정하는 함수\n",
    "def read_and_resize(file_path, target_size=(10, 10)):\n",
    "    img = Image.open(file_path)\n",
    "    img = img.resize(target_size, Image.ANTIALIAS)\n",
    "    return np.array(img)\n",
    "\n",
    "# 각각의 이미지 파일이 저장된 폴더 경로\n",
    "open_folder_path = \".media/openLip/\"\n",
    "close_folder_path = \".media/closeLip/\"\n",
    "\n",
    "# 각 폴더에 있는 이미지 파일들의 경로를 리스트로 수집\n",
    "open_image_files = [os.path.join(open_folder_path, f) for f in os.listdir(open_folder_path) if f.endswith(\".png\")]\n",
    "close_image_files = [os.path.join(close_folder_path, f) for f in os.listdir(close_folder_path) if f.endswith(\".png\")]\n",
    "\n",
    "# 이미지 데이터를 읽어서 리스트에 추가\n",
    "image_data = []\n",
    "state = []\n",
    "\n",
    "# 하품 사진 추가\n",
    "for open_file in open_image_files:\n",
    "    open_data = read_and_resize(open_file)\n",
    "    image_data.append(open_data)\n",
    "    state.append(\"open\")\n",
    "\n",
    "# 입 닫거나 말하는 사진 추가\n",
    "for close_file in close_image_files:\n",
    "    close_data = read_and_resize(close_file)\n",
    "    image_data.append(close_data)\n",
    "    state.append(\"close\")\n",
    "\n",
    "# 데이터셋 생성\n",
    "data = pd.DataFrame({\"state\": state, \"image\": image_data})\n",
    "\n",
    "# 데이터를 랜덤하게 섞은 후 훈련 데이터와 검증 데이터로 분할\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# CSV 파일로 저장\n",
    "print(\"image_data\", np.array(image_data))\n",
    "print(\"data\", data)\n",
    "data.to_csv(\"dataset/lip/dataset.csv\", index=False)\n",
    "train_data.to_csv(\"dataset/lip/train_dataset.csv\")\n",
    "val_data.to_csv(\"dataset/lip/val_dataset.csv\")\n",
    "\n",
    "# 이미지 데이터를 NumPy 배열로 변환\n",
    "x_train = np.array(train_data[\"image\"].tolist()).astype(np.float32)\n",
    "x_val = np.array(val_data[\"image\"].tolist()).astype(np.float32)\n",
    "\n",
    "# 레이블을 NumPy 배열로 변환\n",
    "y_train = np.array(train_data[\"state\"].map({\"open\": 1, \"close\": 0})).reshape(-1, 1).astype(np.float32)\n",
    "y_val = np.array(val_data[\"state\"].map({\"open\": 1, \"close\": 0})).reshape(-1, 1).astype(np.float32)\n",
    "\n",
    "# NumPy 배열을 파일로 저장\n",
    "np.save(\"dataset/lip/x_train.npy\", x_train)\n",
    "np.save(\"dataset/lip/x_val.npy\", x_val)\n",
    "np.save(\"dataset/lip/y_train.npy\", y_train)\n",
    "np.save(\"dataset/lip/y_val.npy\", y_val)\n",
    "\n",
    "# 출력 확인\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
