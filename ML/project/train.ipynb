{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime  # 현재 날짜와 시간을 기록하기 위한 datetime 라이브러리\n",
    "import numpy as np  # 수학 및 배열 관련 작업을 위한 numpy 라이브러리\n",
    "import matplotlib.pyplot as plt  # 그래픽 시각화를 위한 matplotlib.pyplot 라이브러리\n",
    "from keras.layers import Input, Activation, Conv2D, Flatten, Dense, MaxPooling2D  # Keras에서 사용되는 레이어 모듈\n",
    "from keras.models import Model, load_model  # Keras에서 모델 구축 및 불러오기를 위한 모듈\n",
    "from keras.preprocessing.image import ImageDataGenerator  # 이미지 데이터를 증강하고 전처리하기 위한 모듈\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau  # 모델 학습 중 사용되는 콜백 함수들\n",
    "\n",
    "# 시각화 스타일을 dark_background로 설정\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "내 눈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1615, 26, 34) (1615, 1)\n",
      "(404, 26, 34) (404, 1)\n"
     ]
    }
   ],
   "source": [
    "# 'newDataset' 디렉토리에서 훈련 데이터와 레이블, 검증 데이터와 레이블을 불러옴\n",
    "x_train = np.load('dataset/eye/x_train.npy').astype(np.float32)  # 훈련 데이터 불러오기 및 데이터 타입을 float32로 변환\n",
    "y_train = np.load('dataset/eye/y_train.npy').astype(np.float32)  # 훈련 레이블 불러오기 및 데이터 타입을 float32로 변환\n",
    "x_val = np.load('dataset/eye/x_val.npy').astype(np.float32)  # 검증 데이터 불러오기 및 데이터 타입을 float32로 변환\n",
    "y_val = np.load('dataset/eye/y_val.npy').astype(np.float32)  # 검증 레이블 불러오기 및 데이터 타입을 float32로 변환\n",
    "\n",
    "# 불러온 데이터의 형태 출력\n",
    "print(x_train.shape, y_train.shape)  # 훈련 데이터의 형태 출력: (1615, 26, 34) - 1615개의 샘플, 각각의 샘플은 26x34 크기의 이미지\n",
    "print(x_val.shape, y_val.shape)  # 검증 데이터의 형태 출력: (404, 26, 34) - 404개의 샘플, 각각의 샘플은 26x34 크기의 이미지\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "내 입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 10, 10) (1600, 1)\n",
      "(400, 10, 10) (400, 1)\n"
     ]
    }
   ],
   "source": [
    "# 'newDataset' 디렉토리에서 훈련 데이터와 레이블, 검증 데이터와 레이블을 불러옴\n",
    "x_train = np.load('dataset/lip/x_train.npy').astype(np.float32)  # 훈련 데이터 불러오기 및 데이터 타입을 float32로 변환\n",
    "y_train = np.load('dataset/lip/y_train.npy').astype(np.float32)  # 훈련 레이블 불러오기 및 데이터 타입을 float32로 변환\n",
    "x_val = np.load('dataset/lip/x_val.npy').astype(np.float32)  # 검증 데이터 불러오기 및 데이터 타입을 float32로 변환\n",
    "y_val = np.load('dataset/lip/y_val.npy').astype(np.float32)  # 검증 레이블 불러오기 및 데이터 타입을 float32로 변환\n",
    "\n",
    "# 불러온 데이터의 형태 출력\n",
    "print(x_train.shape, y_train.shape)  # 훈련 데이터의 형태 출력: (1600, 10, 10) - 1600개의 샘플, 각각의 샘플은 10x10 크기의 이미지\n",
    "print(x_val.shape, y_val.shape)  # 검증 데이터의 형태 출력: (400, 10, 10) - 400개의 샘플, 각각의 샘플은 10x10 크기의 이미지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# ImageDataGenerator 정의\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 이미지 데이터의 shape을 (이미지 수, 높이, 너비, 채널)로 변경\n",
    "x_train = x_train.reshape(x_train.shape[0], 10, 10, 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], 10, 10, 1)\n",
    "\n",
    "# flow 메서드를 사용하여 데이터 생성\n",
    "train_generator = train_datagen.flow(\n",
    "    x=x_train, y=y_train,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow(\n",
    "    x=x_val, y=y_val,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10, 10, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 10, 10, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 5, 5, 32)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 5, 5, 64)          18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 2, 2, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 2, 2, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 1, 1, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               66048     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 159233 (622.00 KB)\n",
      "Trainable params: 159233 (622.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(10, 10, 1))\n",
    "\n",
    "net = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(inputs)\n",
    "net = MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n",
    "net = MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n",
    "net = MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = Flatten()(net)\n",
    "\n",
    "net = Dense(512)(net)\n",
    "net = Activation('relu')(net)\n",
    "net = Dense(1)(net)\n",
    "outputs = Activation('sigmoid')(net)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wl/5h8ygnjj29ndbpccd4zxqbfh0000gn/T/ipykernel_23887/3027296455.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/50 [============================>.] - ETA: 0s - loss: 0.3773 - acc: 0.8106\n",
      "Epoch 1: val_acc improved from -inf to 0.91000, saving model to models/2024_01_03_14_14_47.h5\n",
      "50/50 [==============================] - 1s 6ms/step - loss: 0.3751 - acc: 0.8112 - val_loss: 0.2543 - val_acc: 0.9100 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 0.1467 - acc: 0.9477"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shinjongsoo/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_acc improved from 0.91000 to 0.96500, saving model to models/2024_01_03_14_14_47.h5\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1438 - acc: 0.9500 - val_loss: 0.1042 - val_acc: 0.9650 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1204 - acc: 0.9588\n",
      "Epoch 3: val_acc did not improve from 0.96500\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.1204 - acc: 0.9588 - val_loss: 0.1626 - val_acc: 0.9375 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 0.1053 - acc: 0.9673\n",
      "Epoch 4: val_acc improved from 0.96500 to 0.99000, saving model to models/2024_01_03_14_14_47.h5\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.1012 - acc: 0.9675 - val_loss: 0.0396 - val_acc: 0.9900 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.0772 - acc: 0.9753\n",
      "Epoch 5: val_acc did not improve from 0.99000\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0762 - acc: 0.9756 - val_loss: 0.0425 - val_acc: 0.9900 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 0.0689 - acc: 0.9796\n",
      "Epoch 6: val_acc improved from 0.99000 to 0.99500, saving model to models/2024_01_03_14_14_47.h5\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0690 - acc: 0.9794 - val_loss: 0.0161 - val_acc: 0.9950 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 0.0680 - acc: 0.9773\n",
      "Epoch 7: val_acc did not improve from 0.99500\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0668 - acc: 0.9775 - val_loss: 0.0254 - val_acc: 0.9925 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 0.0812 - acc: 0.9762\n",
      "Epoch 8: val_acc did not improve from 0.99500\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0837 - acc: 0.9756 - val_loss: 0.0506 - val_acc: 0.9875 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 0.0494 - acc: 0.9865\n",
      "Epoch 9: val_acc did not improve from 0.99500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0506 - acc: 0.9862 - val_loss: 0.0086 - val_acc: 0.9950 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 0.0556 - acc: 0.9847\n",
      "Epoch 10: val_acc did not improve from 0.99500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0533 - acc: 0.9844 - val_loss: 0.0186 - val_acc: 0.9925 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "42/50 [========================>.....] - ETA: 0s - loss: 0.0535 - acc: 0.9859\n",
      "Epoch 11: val_acc did not improve from 0.99500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0482 - acc: 0.9869 - val_loss: 0.0229 - val_acc: 0.9925 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9892\n",
      "Epoch 12: val_acc did not improve from 0.99500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0371 - acc: 0.9894 - val_loss: 0.0092 - val_acc: 0.9950 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 0.0510 - acc: 0.9847\n",
      "Epoch 13: val_acc did not improve from 0.99500\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0510 - acc: 0.9850 - val_loss: 0.0238 - val_acc: 0.9925 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 0.0283 - acc: 0.9929\n",
      "Epoch 14: val_acc improved from 0.99500 to 1.00000, saving model to models/2024_01_03_14_14_47.h5\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0291 - acc: 0.9931 - val_loss: 0.0031 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 0.0348 - acc: 0.9885\n",
      "Epoch 15: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0332 - acc: 0.9887 - val_loss: 0.0087 - val_acc: 0.9975 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 0.0337 - acc: 0.9924\n",
      "Epoch 16: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0319 - acc: 0.9931 - val_loss: 0.0339 - val_acc: 0.9900 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9904\n",
      "Epoch 17: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0268 - acc: 0.9906 - val_loss: 0.0023 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "42/50 [========================>.....] - ETA: 0s - loss: 0.0282 - acc: 0.9911\n",
      "Epoch 18: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0240 - acc: 0.9925 - val_loss: 0.0023 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 0.0250 - acc: 0.9927\n",
      "Epoch 19: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0236 - acc: 0.9931 - val_loss: 0.0092 - val_acc: 0.9975 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 0.0324 - acc: 0.9879\n",
      "Epoch 20: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0307 - acc: 0.9887 - val_loss: 0.0030 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 0.0260 - acc: 0.9942\n",
      "Epoch 21: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0244 - acc: 0.9944 - val_loss: 0.0074 - val_acc: 0.9975 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 0.0231 - acc: 0.9935\n",
      "Epoch 22: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0218 - acc: 0.9937 - val_loss: 0.0028 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.0233 - acc: 0.9941\n",
      "Epoch 23: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0231 - acc: 0.9937 - val_loss: 0.0064 - val_acc: 0.9975 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 0.0353 - acc: 0.9893\n",
      "Epoch 24: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0375 - acc: 0.9881 - val_loss: 0.0021 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 0.0226 - acc: 0.9936\n",
      "Epoch 25: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0222 - acc: 0.9937 - val_loss: 0.0070 - val_acc: 0.9975 - lr: 2.0000e-04\n",
      "Epoch 26/50\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 0.0139 - acc: 0.9985\n",
      "Epoch 26: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0130 - acc: 0.9981 - val_loss: 0.0048 - val_acc: 0.9975 - lr: 2.0000e-04\n",
      "Epoch 27/50\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 0.0169 - acc: 0.9950\n",
      "Epoch 27: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0160 - acc: 0.9956 - val_loss: 0.0057 - val_acc: 0.9975 - lr: 2.0000e-04\n",
      "Epoch 28/50\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 0.0172 - acc: 0.9950\n",
      "Epoch 28: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0159 - acc: 0.9956 - val_loss: 0.0049 - val_acc: 0.9975 - lr: 2.0000e-04\n",
      "Epoch 29/50\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9955\n",
      "Epoch 29: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0190 - acc: 0.9956 - val_loss: 0.0041 - val_acc: 0.9975 - lr: 2.0000e-04\n",
      "Epoch 30/50\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.0133 - acc: 0.9974\n",
      "Epoch 30: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0129 - acc: 0.9975 - val_loss: 0.0047 - val_acc: 0.9975 - lr: 2.0000e-04\n",
      "Epoch 31/50\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 0.0143 - acc: 0.9965\n",
      "Epoch 31: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0131 - acc: 0.9969 - val_loss: 0.0012 - val_acc: 1.0000 - lr: 2.0000e-04\n",
      "Epoch 32/50\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 0.0130 - acc: 0.9951 \n",
      "Epoch 32: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0138 - acc: 0.9950 - val_loss: 0.0050 - val_acc: 0.9975 - lr: 2.0000e-04\n",
      "Epoch 33/50\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 0.0117 - acc: 0.9967\n",
      "Epoch 33: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0113 - acc: 0.9969 - val_loss: 0.0081 - val_acc: 0.9975 - lr: 2.0000e-04\n",
      "Epoch 34/50\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 0.0163 - acc: 0.9960\n",
      "Epoch 34: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0155 - acc: 0.9962 - val_loss: 0.0031 - val_acc: 0.9975 - lr: 2.0000e-04\n",
      "Epoch 35/50\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 0.0133 - acc: 0.9956\n",
      "Epoch 35: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0120 - acc: 0.9962 - val_loss: 0.0033 - val_acc: 0.9975 - lr: 4.0000e-05\n",
      "Epoch 36/50\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 0.0132 - acc: 0.9973 \n",
      "Epoch 36: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0158 - acc: 0.9962 - val_loss: 0.0038 - val_acc: 0.9975 - lr: 4.0000e-05\n",
      "Epoch 37/50\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 0.0121 - acc: 0.9979 \n",
      "Epoch 37: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0114 - acc: 0.9981 - val_loss: 0.0047 - val_acc: 0.9975 - lr: 4.0000e-05\n",
      "Epoch 38/50\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 0.0112 - acc: 0.9966\n",
      "Epoch 38: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0104 - acc: 0.9969 - val_loss: 0.0030 - val_acc: 0.9975 - lr: 4.0000e-05\n",
      "Epoch 39/50\n",
      "48/50 [===========================>..] - ETA: 0s - loss: 0.0108 - acc: 0.9974\n",
      "Epoch 39: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0104 - acc: 0.9975 - val_loss: 0.0034 - val_acc: 0.9975 - lr: 4.0000e-05\n",
      "Epoch 40/50\n",
      "42/50 [========================>.....] - ETA: 0s - loss: 0.0101 - acc: 0.9963\n",
      "Epoch 40: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0090 - acc: 0.9969 - val_loss: 0.0029 - val_acc: 0.9975 - lr: 4.0000e-05\n",
      "Epoch 41/50\n",
      "46/50 [==========================>...] - ETA: 0s - loss: 0.0120 - acc: 0.9966\n",
      "Epoch 41: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0117 - acc: 0.9969 - val_loss: 0.0038 - val_acc: 0.9975 - lr: 4.0000e-05\n",
      "Epoch 42/50\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 0.0056 - acc: 0.9986\n",
      "Epoch 42: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0110 - acc: 0.9969 - val_loss: 0.0036 - val_acc: 0.9975 - lr: 4.0000e-05\n",
      "Epoch 43/50\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 0.0078 - acc: 0.9979\n",
      "Epoch 43: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0103 - acc: 0.9969 - val_loss: 0.0031 - val_acc: 0.9975 - lr: 4.0000e-05\n",
      "Epoch 44/50\n",
      "43/50 [========================>.....] - ETA: 0s - loss: 0.0079 - acc: 0.9964\n",
      "Epoch 44: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0071 - acc: 0.9969 - val_loss: 0.0024 - val_acc: 0.9975 - lr: 4.0000e-05\n",
      "Epoch 45/50\n",
      "44/50 [=========================>....] - ETA: 0s - loss: 0.0053 - acc: 0.9979 \n",
      "Epoch 45: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0101 - acc: 0.9969 - val_loss: 0.0027 - val_acc: 0.9975 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9962\n",
      "Epoch 46: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0126 - acc: 0.9962 - val_loss: 0.0030 - val_acc: 0.9975 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9987\n",
      "Epoch 47: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0076 - acc: 0.9987 - val_loss: 0.0029 - val_acc: 0.9975 - lr: 1.0000e-05\n",
      "Epoch 48/50\n",
      "41/50 [=======================>......] - ETA: 0s - loss: 0.0119 - acc: 0.9970 \n",
      "Epoch 48: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0111 - acc: 0.9975 - val_loss: 0.0031 - val_acc: 0.9975 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "45/50 [==========================>...] - ETA: 0s - loss: 0.0092 - acc: 0.9965\n",
      "Epoch 49: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0085 - acc: 0.9969 - val_loss: 0.0029 - val_acc: 0.9975 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "47/50 [===========================>..] - ETA: 0s - loss: 0.0075 - acc: 0.9980\n",
      "Epoch 50: val_acc did not improve from 1.00000\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.0074 - acc: 0.9981 - val_loss: 0.0029 - val_acc: 0.9975 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16c890510>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator, epochs=50, validation_data=val_generator,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/%s.h5' % (start_time), monitor='val_acc', save_best_only=True, mode='max', verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=10, verbose=1, mode='auto', min_lr=1e-05)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step\n",
      "test acc: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "model = load_model('models/%s.h5' % (start_time))\n",
    "\n",
    "y_pred = model.predict(x_val/255.)\n",
    "y_pred_logical = (y_pred > 0.5).astype(int)\n",
    "\n",
    "print ('test acc: %s' % accuracy_score(y_val, y_pred_logical))\n",
    "cm = confusion_matrix(y_val, y_pred_logical)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
