{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "얼굴 인식하고 해당 위치에 텍스트, 사각형 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture(1) # 디바이스 아이디\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 2560)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 1440)\n",
    "\n",
    "# 얼굴 인식을 위해 얼굴 검출기를 로드합니다.\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "while cv2.waitKey(10) < 0: # wait를 늘리면 프레임이 줄어듬\n",
    "    ret, frame = capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # 그레이로 만들어서 연산속도를 높이고\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)) # 얼굴 검출을 돌려 x,y,w,h값을 반환\n",
    "    # face = faces[0]\n",
    "    # frame = cv2.putText(frame, 'Face', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2) # x,y값 위치에 텍스트 삽입\n",
    "    # frame = cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 5, cv2.LINE_8 )# x,y값 꼭지점, 위치에 텍스트 삽입\n",
    "    # 검출된 얼굴 주위에 사각형을 그립니다.\n",
    "    for (x, y, w, h) in faces:\n",
    "        frame = cv2.putText(frame, 'Face', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2) # x,y값 위치에 텍스트 삽입\n",
    "        frame = cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 5, cv2.LINE_8 )# x,y값 꼭지점, 위치에 텍스트 삽입\n",
    "    cv2.imshow(\"VideoFrame\", frame)\n",
    "\n",
    "\n",
    "capture.release()\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한글 사용?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "\n",
    "def pilPutText(src, text, pos, font_size, font_color):\n",
    "    img_pil = Image.fromarray(src)\n",
    "    draw = ImageDraw.Draw(img_pil)\n",
    "    font = ImageFont.truetype(\"fonts/gulim.ttc\", font_size)\n",
    "    draw.text(pos, text, font=font, fill=font_color)\n",
    "    return np.array(img_pil)\n",
    "\n",
    "img = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "img = pilPutText(img, \"안녕\", (30, 30), 30, (0, 255, 255))\n",
    "\n",
    "cv2.imshow(\"text\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture(\"data/sample_1280x720_surfing_with_audio.avi\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "record = False\n",
    "\n",
    "while True:\n",
    "    if(capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT)-1):\n",
    "        capture.open(\"./deeplearning/opencv/sample_1280x720_surfing_with_audio.avi\")\n",
    "\n",
    "    ret, frame = capture.read()\n",
    "    cv2.imshow(\"VideoFrame\", frame)\n",
    "\n",
    "    now = datetime.datetime.now().strftime(\"%d_%H-%M-%S\")\n",
    "    key = cv2.waitKey(33)\n",
    "\n",
    "    if key == 27: #ESC\n",
    "        break\n",
    "    elif key == ord('c'):\n",
    "        print(\"캡쳐\")\n",
    "        cv2.imwrite(\"/Users/shinjongsoo/Desktop/codingOn/ML/practice/data/\" + str(now) + \".png\", frame)\n",
    "    elif key == ord('r'):\n",
    "        print(\"녹화 시작\")\n",
    "        record = True\n",
    "        video = cv2.VideoWriter(\"/Users/shinjongsoo/Desktop/codingOn/ML/practice/data/\" + str(now) + \".avi\", fourcc, 20.0, (frame.shape[1], frame.shape[0]))\n",
    "    elif key == ord('s'):\n",
    "        print(\"녹화 중지\")\n",
    "        record = False\n",
    "        video.release()\n",
    "        \n",
    "    if record == True:\n",
    "        print(\"녹화 중..\")\n",
    "        video.write(frame)\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "\n",
    "capture = cv2.VideoCapture(1) # 디바이스 아이디\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 2560)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 1440)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "record = False\n",
    "\n",
    "while True: # wait를 늘리면 프레임이 줄어듬\n",
    "    ret, frame = capture.read()\n",
    "    cv2.imshow(\"VideoFrame\", frame)\n",
    "\n",
    "    now = datetime.datetime.now().strftime(\"%d_%H-%M-%S\")\n",
    "    key = cv2.waitKey(33)\n",
    "\n",
    "    if key == 27: #ESC\n",
    "        break\n",
    "    elif key == ord('c'):\n",
    "        print(\"캡쳐\")\n",
    "        cv2.imwrite(\"/Users/shinjongsoo/Desktop/codingOn/ML/practice/data/\" + str(now) + \".png\", frame)\n",
    "    elif key == ord('r'):\n",
    "        print(\"녹화 시작\")\n",
    "        record = True\n",
    "        video = cv2.VideoWriter(\"/Users/shinjongsoo/Desktop/codingOn/ML/practice/data/\" + str(now) + \".avi\", fourcc, 20.0, (frame.shape[1], frame.shape[0]))\n",
    "    elif key == ord('s'):\n",
    "        print(\"녹화 중지\")\n",
    "        record = False\n",
    "        video.release()\n",
    "        \n",
    "    if record == True:\n",
    "        print(\"녹화 중..\")\n",
    "        video.write(frame)\n",
    "\n",
    "\n",
    "capture.release()\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마우스 클릭하면 원 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def mouse_event(event, x, y, flags, param):\n",
    "    # print(\"event x y flags\", event, x, y, flags)\n",
    "    diff = 2\n",
    "    global radius\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(param, (x, y), radius, (255, 0, 0), 2)\n",
    "        cv2.imshow(\"draw\", src)\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEWHEEL:\n",
    "        if flags > 0:\n",
    "            radius += diff\n",
    "        elif radius > 1:\n",
    "            radius -= diff\n",
    "\n",
    "radius = 5\n",
    "src = np.full((500, 500, 3), 255, dtype=np.uint8)\n",
    "\n",
    "cv2.imshow(\"draw\", src)\n",
    "cv2.setMouseCallback(\"draw\", mouse_event, src)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "화면에 오른쪽 클릭하면 원 출력(없어지지 않게)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#실습 5\n",
    "\n",
    "import cv2\n",
    "\n",
    "history = []\n",
    "radius = 5\n",
    "\n",
    "def mouse_event(event, x, y, flags, param):\n",
    "    # print(\"event x y flags\", event, x, y, flags)\n",
    "    diff = 2\n",
    "    global radius\n",
    "\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        history.append((x, y))\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEWHEEL:\n",
    "        if flags > 0:\n",
    "            radius += diff\n",
    "        elif radius > 1:\n",
    "            radius -= diff\n",
    "\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "# capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "# capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "cv2.namedWindow(\"VideoFrame\")\n",
    "cv2.setMouseCallback(\"VideoFrame\", mouse_event)\n",
    "\n",
    "while cv2.waitKey(10) < 0:\n",
    "    ret, frame = capture.read()\n",
    "    for x, y in history:\n",
    "        cv2.circle(frame, (x, y), radius, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"VideoFrame\", frame)\n",
    "\n",
    "capture.release()\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture(0) # 디바이스 아이디\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 2560)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 1440)\n",
    "\n",
    "\n",
    "while cv2.waitKey(10) < 0: # wait를 늘리면 프레임이 줄어듬\n",
    "    ret, frame = capture.read()\n",
    "    # frame = cv2.blur(frame,ksize=(20,20),anchor=(-1,-1)) # 블러\n",
    "    frame = cv2.Canny(frame, 10, 200) # 가장자리 검출\n",
    "    cv2.imshow(\"VideoFrame\", frame)\n",
    "\n",
    "\n",
    "capture.release()\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def onChange(pos):\n",
    "    pass\n",
    "\n",
    "# src = cv2.imread(\"data/cabi.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "cv2.namedWindow(\"Trackbar Windows\")\n",
    "\n",
    "cv2.createTrackbar(\"threshold\", \"Trackbar Windows\", 0, 255, onChange)\n",
    "cv2.createTrackbar(\"maxValue\", \"Trackbar Windows\", 0, 255, lambda x : x)\n",
    "\n",
    "cv2.setTrackbarPos(\"threshold\", \"Trackbar Windows\", 127)\n",
    "cv2.setTrackbarPos(\"maxValue\", \"Trackbar Windows\", 255)\n",
    "\n",
    "\n",
    "capture = cv2.VideoCapture(0) # 디바이스 아이디\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 2560)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 1440)\n",
    "\n",
    "while cv2.waitKey(1) != ord('q'):\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.IMREAD_GRAYSCALE\n",
    "    thresh = cv2.getTrackbarPos(\"threshold\", \"Trackbar Windows\")\n",
    "    maxval = cv2.getTrackbarPos(\"maxValue\", \"Trackbar Windows\")\n",
    "\n",
    "    _, binary = cv2.threshold(frame, thresh, maxval, cv2.THRESH_BINARY)\n",
    "\n",
    "    cv2.imshow(\"Trackbar Windows\", binary)\n",
    "\n",
    "capture.release()\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"data/cabi.jpg\")\n",
    "dst = src.copy()\n",
    "\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_RGB2GRAY)\n",
    "corners = cv2.goodFeaturesToTrack(gray, 100, 0.01, 5, blockSize=3, useHarrisDetector=True, k=0.03)\n",
    "\n",
    "for i in corners:\n",
    "    cv2.circle(dst, tuple(map(int, i[0])), 3, (0, 0, 255), 2)\n",
    "\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"data/hats.webp\", cv2.IMREAD_GRAYSCALE)\n",
    "templit = cv2.imread(\"data/hat.webp\", cv2.IMREAD_GRAYSCALE)\n",
    "dst = cv2.imread(\"data/hats.webp\")\n",
    "\n",
    "result = cv2.matchTemplate(src, templit, cv2.TM_SQDIFF_NORMED)\n",
    "\n",
    "minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(result)\n",
    "x, y = minLoc\n",
    "h, w = templit.shape\n",
    "print(result)\n",
    "print(x, y)\n",
    "\n",
    "dst = cv2.rectangle(dst, (x, y), (x +  w, y + h) , (0, 0, 255), 1)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model  # TensorFlow is required for Keras to work\n",
    "import cv2  # Install opencv-python\n",
    "import numpy as np\n",
    "\n",
    "# Disable scientific notation for clarity\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Load the model\n",
    "model = load_model(\"keras_Model.h5\", compile=False)\n",
    "\n",
    "# Load the labels\n",
    "class_names = open(\"labels.txt\", \"r\").readlines()\n",
    "\n",
    "# CAMERA can be 0 or 1 based on default camera of your computer\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Grab the webcamera's image.\n",
    "    ret, image = camera.read()\n",
    "\n",
    "    # Resize the raw image into (224-height,224-width) pixels\n",
    "    image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Show the image in a window\n",
    "    cv2.imshow(\"Webcam Image\", image)\n",
    "\n",
    "    # Make the image a numpy array and reshape it to the models input shape.\n",
    "    image = np.asarray(image, dtype=np.float32).reshape(1, 224, 224, 3)\n",
    "\n",
    "    # Normalize the image array\n",
    "    image = (image / 127.5) - 1\n",
    "\n",
    "    # Predicts the model\n",
    "    prediction = model.predict(image)\n",
    "    index = np.argmax(prediction)\n",
    "    class_name = class_names[index]\n",
    "    confidence_score = prediction[0][index]\n",
    "\n",
    "    # Print prediction and confidence score\n",
    "    print(\"Class:\", class_name[2:], end=\"\")\n",
    "    print(\"Confidence Score:\", str(np.round(confidence_score * 100))[:-2], \"%\")\n",
    "\n",
    "    # Listen to the keyboard for presses.\n",
    "    keyboard_input = cv2.waitKey(1)\n",
    "\n",
    "    # 27 is the ASCII for the esc key on your keyboard.\n",
    "    if keyboard_input == 27:\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
